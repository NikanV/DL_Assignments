{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yKp1NLIIia1"
      },
      "source": [
        "<img src='sharif_logo.png' alt=\"SUT logo\" width=150 height=150 align=left class=\"saturate\" >\n",
        "\n",
        "<br>\n",
        "<font face=\"Times New Roman\">\n",
        "<div dir=ltr align=center>\n",
        "<font color=0F5298 size=7>\n",
        " Deep Learning <br>\n",
        "<font color=2565AE size=5>\n",
        "Computer Engineering Department - Spring 2025  <br>\n",
        "<font color=3C99D size=5>\n",
        "          Homework 2:  <br>\n",
        "<font color=696880 size=4>\n",
        "           \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2RL2uBQ9_cj"
      },
      "source": [
        "**Name**: Nikan Vasei  \n",
        "  \n",
        "**Student Code**: 400105303"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color='cyan'>\n",
        "\n",
        "## Some Notes & Reflections\n",
        "\n",
        "Throughout this project, I implemented and evaluated several reasoning strategies as intended, including Chain of Thought (CoT) prompting, best-of-n, beam search, and Self-Refinement, to improve the model's performance on mathematical problems. While the overall structure and logic of the implementation were solid, a number of practical limitations affected the quality of the results:\n",
        "\n",
        "- **Frequent Colab Disconnects**: Repeated disconnections forced me to restart the notebook multiple times, which interrupted long-running processes and slowed down experimentation. It took so long for me to be able to fully run the notebook :(\n",
        "    - Also hosting the model via VLLM occasionally caused disconnections, further complicating the evaluation loop.\n",
        "\n",
        "- **Token Limitations**: Due to output length restrictions (which was about 5k), some model completions were cut off prematurely, often missing the final answer in the required \\\\boxed{} format. This also causes the benchmark to count that answer as a wrong one (Those kinds of answers are shown as `None` in cell outputs).\n",
        "\n",
        "- **Limited Parameter Tuning**: Parameters such as temperature, top_p, and beam width had a significant impact on output quality, but time and platform constraints limited my ability to fine-tune them thoroughly. (Obviously we could get better results, if we had fine-tuned them more.)\n",
        "\n",
        "Despite these challenges, the implementation demonstrates how each reasoning strategy influences model performance. The results show promising trends and highlight the strengths and trade-offs of each approach, especially in terms of coherence, completeness, and correctness of answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21D9mE3q9yjt"
      },
      "source": [
        "# Assignment Overview\n",
        "\n",
        "In this assignment, you will explore inference scaling techniques in large language models (LLMs) and evaluate their performance using the Math Benchmark. Throughout the notebook, you will learn about several inference methods, including:\n",
        "\n",
        "- **Chain-of-Thought (CoT):** A method where the model generates intermediate reasoning steps before providing the final answer.\n",
        "- **Best-of-n Sampling:** An approach that generates multiple candidate responses and selects the best one based on a scoring function.\n",
        "- **Beam Search:** A technique that expands several possible sequences simultaneously, choosing the most promising ones based on probability.\n",
        "- **Self-Refinement:** An iterative process where the model revises its output to improve accuracy and coherence.\n",
        "\n",
        "The **Math Benchmark** is a suite of challenging mathematical problems designed to test the reasoning and problem-solving capabilities of LLMs. The benchmark includes a variety of questions ranging from basic arithmetic and algebra to more advanced topics such as geometry and calculus. For example, you might be asked to solve an equation like `2x + 5 = 15` or compute the derivative of a function, tasks that assess the model's ability to handle both straightforward and complex mathematical queries.\n",
        "\n",
        "By the end of this assignment, you will have:\n",
        "- Gained a deeper understanding of inference time scaling methods in LLMs.\n",
        "- Compared the effectiveness of different inference techniques using a rigorous math evaluation framework.\n",
        "\n",
        "Let's dive into the notebook and begin exploring how these methods perform on a challenging set of math problems!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvmuU1-V9yju"
      },
      "source": [
        "## vLLM: Accelerated Inference Engine for LLMs\n",
        "\n",
        "vLLM is an open-source project designed to optimize the loading and inference of large language models. By leveraging advanced memory management techniques and dynamic batching, vLLM significantly speeds up the inference process, making it easier to deploy and experiment with LLMs even on hardware with limited resources\n",
        "So we use vLLM to get results faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHaWOEvt9yju"
      },
      "source": [
        "# installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UyG3Ng0jIl7m",
        "outputId": "280f0a36-c53f-4e10-cc08-88bf3a04041c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.8.5.post1-cp38-abi3-manylinux1_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.51.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm) (0.30.2)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (5.29.4)\n",
            "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.76.2)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.4)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.9 (from vllm)\n",
            "  Downloading llguidance-0.7.19-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting outlines==0.1.11 (from vllm)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.18 (from vllm)\n",
            "  Downloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.13.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting pyzmq>=25.0.0 (from vllm)\n",
            "  Downloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.7.0)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm)\n",
            "  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.9.3 (from vllm)\n",
            "  Downloading compressed_tensors-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.18.0 (from vllm)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-json-logger (from vllm)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.2)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting opentelemetry-sdk<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp<1.27.0,>=1.26.0 (from vllm)\n",
            "  Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 (from vllm)\n",
            "  Downloading opentelemetry_semantic_conventions_ai-0.4.8-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
            "  Downloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0+cu124)\n",
            "Collecting xformers==0.0.29.post2 (from vllm)\n",
            "  Downloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting astor (from depyf==0.18.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from depyf==0.18.0->vllm)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting interegular (from outlines==0.1.11->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
            "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm) (1.3.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting uvicorn>=0.12.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (24.2)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface-hub[hf_xet]>=0.30.0->vllm)\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
            "Collecting importlib_metadata (from vllm)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.26.0 (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from vllm)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm)\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.4.26)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.1->vllm) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.3)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.14.5-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.8.5.post1-cp38-abi3-manylinux1_x86_64.whl (326.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.4/326.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.9.3-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.4/98.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post2-cp311-cp311-manylinux_2_28_x86_64.whl (44.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.16.3-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.4/94.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.19-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.26.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.26.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions_ai-0.4.8-py3-none-any.whl (5.6 kB)\n",
            "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzmq-26.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.4/862.4 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.46.0-cp311-cp311-manylinux2014_x86_64.whl (68.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich_toolkit-0.14.5-py3-none-any.whl (24 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blake3, uvloop, uvicorn, pyzmq, python-multipart, python-json-logger, python-dotenv, pycountry, protobuf, partial-json-parser, opentelemetry-semantic-conventions-ai, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, msgspec, llvmlite, llguidance, lark, interegular, importlib_metadata, httptools, hf-xet, gguf, dnspython, diskcache, dill, astor, airportsdata, watchfiles, tiktoken, starlette, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, email-validator, depyf, rich-toolkit, prometheus-fastapi-instrumentator, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, nvidia-cusolver-cu12, lm-format-enforcer, fastapi, ray, outlines_core, opentelemetry-sdk, mistral_common, fastapi-cli, xgrammar, xformers, outlines, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, compressed-tensors, opentelemetry-exporter-otlp, vllm\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 24.0.1\n",
            "    Uninstalling pyzmq-24.0.1:\n",
            "      Successfully uninstalled pyzmq-24.0.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed airportsdata-20250224 astor-0.8.1 blake3-1.0.4 compressed-tensors-0.9.3 depyf-0.18.0 dill-0.4.0 diskcache-5.6.3 dnspython-2.7.0 email-validator-2.2.0 fastapi-0.115.12 fastapi-cli-0.0.7 gguf-0.16.3 hf-xet-1.1.0 httptools-0.6.4 importlib_metadata-8.0.0 interegular-0.3.3 lark-1.2.2 llguidance-0.7.19 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.5.4 msgspec-0.19.0 ninja-1.11.1.4 numba-0.61.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-exporter-otlp-proto-http-1.26.0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-semantic-conventions-ai-0.4.8 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.1.0 protobuf-4.25.7 pycountry-24.6.1 python-dotenv-1.1.0 python-json-logger-3.3.0 python-multipart-0.0.20 pyzmq-26.4.0 ray-2.46.0 rich-toolkit-0.14.5 starlette-0.46.2 tiktoken-0.9.0 uvicorn-0.34.2 uvloop-0.21.0 vllm-0.8.5.post1 watchfiles-1.0.5 xformers-0.0.29.post2 xgrammar-0.1.18\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0b9b528b7e274adfb51ab94e51d9bedf",
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWvzLP5FIuc4",
        "outputId": "edff0e95-72f0-4301-f900-cc89442e610d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.4.0\n",
            "    Uninstalling dill-0.4.0:\n",
            "      Successfully uninstalled dill-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY4FWoryOiry"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade numpy\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivC7LIgkLUvR"
      },
      "source": [
        "\n",
        "This command launches a vLLM inference server with:\n",
        "- Model: `DeepSeek-R1-Distill-Qwen-1.5B`\n",
        "- Port: `8000` (default API endpoint)\n",
        "- Precision: `half` (FP16) for memory efficiency\n",
        "- Max context length: `3192` tokens\n",
        "\n",
        "**Note:**  \n",
        "🔹 Ensure you're using a GPU runtime (T4 or better) in Colab  \n",
        "🔹 Only run the next cell if this one executes successfully\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HNmCEaGIzEe"
      },
      "outputs": [],
      "source": [
        "!vllm serve \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"   --port 8000   --dtype=half   --max-model-len 3192"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFPitveIL8PT"
      },
      "source": [
        "* this cell lunches model in background using vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZSaM7q5LrC0",
        "outputId": "041d4234-0b9a-471a-a3da-72c27cd4c10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "!nohup vllm serve \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\" --port 8000 --dtype=half --max-model-len 5192 &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0yGjrAiGXWs"
      },
      "source": [
        "## LLM Query Function\n",
        "\n",
        "* This Python function sends prompts to a locally-hosted LLM API and returns the generated response\n",
        "* you can change max_tokens and temperature as you want\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r-QntB7EF4mb"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "def get_llm_response(prompt):\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "\n",
        "        ],\n",
        "    \"max_tokens\": 2500,\n",
        "    \"temperature\": 0.6\n",
        "    }\n",
        "    response = requests.post(url, json=payload)\n",
        "    return response.json()['choices'][0]['message']['content'].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzqLI_OPMNOD"
      },
      "source": [
        "# Test response generation\n",
        "- testing model with some Math benchmark quesions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PG8o90EML-4",
        "outputId": "314a3945-9ac8-4c25-f761-135244b26d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, so I have these three math questions to solve. Let me take them one by one and think through each step carefully.\n",
            "\n",
            "**First question: How many positive whole-number divisors does 196 have?**\n",
            "\n",
            "Alright, divisors. Hmm, I remember that to find the number of divisors of a number, I should start by factoring it into its prime factors. Then, using the exponents in the prime factorization, I can apply the formula for the number of divisors.\n",
            "\n",
            "So, let's factor 196. I know that 196 is a perfect square because 14 squared is 196. Let me confirm that: 14 times 14 is 196. So, 196 = 14^2. But 14 itself is 2 times 7, so 196 can be written as (2*7)^2, which is 2^2 * 7^2.\n",
            "\n",
            "Wait, hold on. Is that right? Let me check: 2^2 is 4, 7^2 is 49, and 4*49 is 196. Yes, that's correct.\n",
            "\n",
            "So the prime factorization of 196 is 2^2 * 7^2. Now, the formula for the number of divisors is to take the exponents, add one to each, and then multiply them together. So for 2^2, the exponent is 2, so 2+1=3. Similarly, for 7^2, the exponent is 2, so 2+1=3. Then, multiply 3*3, which is 9.\n",
            "\n",
            "Therefore, 196 has 9 positive whole-number divisors. Let me list them to make sure: 1, 2, 4, 7, 14, 28, 49, 98, 196. Yep, that's 9 numbers. So that seems right.\n",
            "\n",
            "**Second question: What is the distance, in units, between the points (2, -6) and (-4, 3)? Express your answer in simplest radical form.**\n",
            "\n",
            "Alright, distance between two points in a plane. I remember the distance formula from coordinate geometry. It's derived from the Pythagorean theorem. The formula is sqrt[(x2 - x1)^2 + (y2 - y1)^2].\n",
            "\n",
            "So, let me identify the coordinates. The first point is (2, -6), so x1=2, y1=-6. The second point is (-4, 3), so x2=-4, y2=3.\n",
            "\n",
            "Now, plug these into the distance formula:\n",
            "\n",
            "Distance = sqrt[(-4 - 2)^2 + (3 - (-6))^2]\n",
            "\n",
            "Let me compute each part step by step.\n",
            "\n",
            "First, the x-component: (-4 - 2) is -6. Squared, that's (-6)^2 = 36.\n",
            "\n",
            "Next, the y-component: (3 - (-6)) is 3 + 6 = 9. Squared, that's 9^2 = 81.\n",
            "\n",
            "Now, add these two results: 36 + 81 = 117.\n",
            "\n",
            "So, the distance is sqrt(117). Hmm, can I simplify sqrt(117)? Let's see. 117 factors into 9 * 13, because 9*13 is 117. And 9 is a perfect square. So sqrt(117) = sqrt(9*13) = sqrt(9)*sqrt(13) = 3*sqrt(13).\n",
            "\n",
            "Therefore, the distance is 3√13 units.\n",
            "\n",
            "Wait, just to double-check: the differences in x and y are (-6) and 9, squared gives 36 and 81, sum is 117, square root is 3√13. Yep, that seems correct.\n",
            "\n",
            "**Third question: Define p and q as sums of reciprocals of k^2 and k^3, respectively. Then, express the double sum from j=1 to infinity and k=1 to infinity of 1/(j + k)^3 in terms of p and q.**\n",
            "\n",
            "Okay, this one is a bit more complex. Let me write down what's given:\n",
            "\n",
            "p = sum_{k=1}^∞ 1/k^2\n",
            "\n",
            "q = sum_{k=1}^∞ 1/k^3\n",
            "\n",
            "And we need to find:\n",
            "\n",
            "sum_{j=1}^∞ sum_{k=1}^∞ 1/(j + k)^3\n",
            "\n",
            "Express this in terms of p and q.\n",
            "\n",
            "Hmm, so we have a double sum over j and k of 1/(j + k)^3. I need to relate this to p and q. Maybe I can find a way to rewrite the double sum in terms of p and q.\n",
            "\n",
            "I know that p is the sum of reciprocals of squares, and q is the sum of reciprocals of cubes. The double sum involves reciprocals of cubes, but with j and k in the denominator, but as (j + k)^3.\n",
            "\n",
            "Let me think about how to manipulate the double sum. Perhaps I can change variables or find a way to express 1/(j + k)^3 in terms of 1/k^3 or something similar.\n",
            "\n",
            "Alternatively, maybe I can switch the order of summation or find a generating function.\n",
            "\n",
            "Wait, another idea: perhaps I can fix j + k and sum over j and k. Let me denote m = j + k. Then, for each m, we can express j as varying from 1 to m -1, and k as m - j.\n",
            "\n",
            "But since j and k both start at 1, m can range from 2 to infinity. So, perhaps I can write the double sum as sum_{m=2}^∞ sum_{j=1}^{m-1} 1/m^3.\n",
            "\n",
            "But wait, is that correct? Because 1/(j + k)^3 = 1/m^3, and for each m, j can be from 1 to m -1, so the inner sum is over j=1 to m-1 of 1/m^3. But that would be (m -1)/m^3.\n",
            "\n",
            "But then the double sum becomes sum_{m=2}^∞ (m - 1)/m^3.\n",
            "\n",
            "Hmm, let's see if that's manageable. Let's compute that.\n",
            "\n",
            "So, sum_{m=2}^∞ (m - 1)/m^3 = sum_{m=2}^∞ [1/m^2 - 1/m^3] = sum_{m=2}^∞ 1/m^2 - sum_{m=2}^∞ 1/m^3\n",
            "\n",
            "But we know that sum_{m=1}^∞ 1/m^2 = p, so sum_{m=2}^∞ 1/m^2 = p - 1.\n",
            "\n",
            "Similarly, sum_{m=1}^∞ 1/m^3 = q, so sum_{m=2}^∞ 1/m^3 = q - 1.\n",
            "\n",
            "Therefore, the double sum becomes (p - 1) - (q - 1) = p - q.\n",
            "\n",
            "Wait, that seems too simple. Let me check if that makes sense.\n",
            "\n",
            "Wait, the double sum was originally over j and k, with each term being 1/(j + k)^3. By changing variables to m = j + k, and then summing over j from 1 to m -1, the term becomes 1/m^3. So, for each m, we have (m -1) terms of 1/m^3.\n",
            "\n",
            "But when we sum over m from 2 to infinity, each term is (m - 1)/m^3, which can be split into 1/m^2 - 1/m^3. So, the total sum is (sum 1/m^2 from m=2 to ∞) - (sum 1/m^3 from m=2 to ∞) = (p - 1) - (q - 1) = p - q.\n",
            "\n",
            "Hmm, that seems correct. So, the double sum is equal to p - q.\n",
            "\n",
            "Wait, but I should make sure that the order of summation doesn't affect the result, but since we are dealing with an infinite series, we need to be careful about convergence. However, since p and q are convergent series, and the double sum is absolutely convergent, Fubini's theorem allows us to switch the order of summation without issues.\n",
            "\n",
            "Therefore, the double sum is p - q.\n",
            "\n",
            "Wait a second, but let me think again. Is that correct? Because the double sum is over j and k, each starting at 1, but when we set m = j + k, m starts at 2, and for each m, j goes from 1 to m -1, so k = m - j goes from m -1 to 1. So, yes, each term is 1/m^3, and the number of terms is (m -1). So, each term is 1/m^3, and we have (m -1) of them, so (m -1)/m^3. Then, summing over m from 2 to infinity, which is p -1 - (q -1) = p - q.\n",
            "\n",
            "Yes, that seems correct.\n",
            "\n",
            "So, the answer is p - q.\n",
            "\n",
            "But wait, hold on. Is the double sum equal to p - q? Let me think about another approach.\n",
            "\n",
            "Alternatively, maybe I can write the double sum as sum_{j=1}^∞ sum_{k=1}^∞ 1/(j + k)^3.\n",
            "\n",
            "Alternatively, perhaps we can write this as sum_{m=2}^∞ sum_{j=1}^{m-1} 1/m^3.\n",
            "\n",
            "Which is the same as sum_{m=2}^∞ (m -1)/m^3.\n",
            "\n",
            "Which is sum_{m=2}^∞ [1/m^2 - 1/m^3] = (p -1) - (q -1) = p - q.\n",
            "\n",
            "Alternatively, perhaps I can think of this as sum_{m=2}^∞ sum_{j=1}^{m-1} 1/m^3.\n",
            "\n",
            "Which is the same as sum_{m=2}^∞ (m -1)/m^3, which is the same as before.\n",
            "\n",
            "Therefore, the conclusion is that the double sum is p - q.\n",
            "\n",
            "Wait, but hold on, p is the sum of 1/k^2 from 1 to infinity, which is known to be π²/6 ≈ 1.6449. Similarly, q is the sum of 1/k^3 from 1 to infinity, which is known as Apery's constant, approximately 1.2020569.\n",
            "\n",
            "So, p - q is approximately 1.6449 - 1.2020569 ≈ 0.4428.\n",
            "\n",
            "But let me compute the double sum numerically to see if that's consistent.\n",
            "\n",
            "Compute the double sum numerically:\n",
            "\n",
            "sum_{j=1}^∞ sum_{k=1}^∞ 1/(j + k)^3.\n",
            "\n",
            "Let me compute partial sums.\n",
            "\n",
            "Compute for j from 1 to, say, 5, and k from 1 to, say, 5, but actually, it's an infinite sum, so we can approximate by summing up to a certain number.\n",
            "\n",
            "But it's tedious, but let me try to approximate the first few terms.\n",
            "\n",
            "Compute for j=1:\n",
            "\n",
            "k=1: 1/(1+1)^3\n"
          ]
        }
      ],
      "source": [
        "# TODO: Generate a response with these Math benchmark quesions\n",
        "question1 = \"How many positive whole-number divisors does 196 have?\"\n",
        "# real answer : 9\n",
        "question2 = \"What is the distance, in units, between the points $(2, -6)$ and $(-4, 3)$? Express your answer in simplest radical form.\"\n",
        "# real answer = 3\\\\sqrt{13}\n",
        "question3 = \"Define\\n\\\\[p = \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{k^2} \\\\quad \\\\text{and} \\\\quad q = \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{k^3}.\\\\]Find a way to write\\n\\\\[\\\\sum_{j = 1}^\\\\infty \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{(j + k)^3}\\\\]in terms of $p$ and $q.$\"\n",
        "# real answer = p - q\n",
        "\n",
        "prompt = f\"\"\"Please answer each of the following math questions step-by-step and briefly.\n",
        "\n",
        "- {question1}\n",
        "\n",
        "- {question2}\n",
        "\n",
        "- {question3}\n",
        "\n",
        "Also make sure to divide each answer by a dash so that they would be easy to follow.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = get_llm_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_m38fk89yjw"
      },
      "source": [
        "# Math Benchmark Evaluation\n",
        "\n",
        "This cell is dedicated to evaluating the performance of inference scaling methods on the Math Benchmark dataset. The process works as follows:\n",
        "\n",
        "- **Dataset Loading:** It loads the MATH-500 dataset, which contains a set of challenging math problems along with their correct solutions.\n",
        "- **Answer Extraction:** The `extract_answer` function is used to parse and extract the final answer from the generated responses. This function specifically looks for a LaTeX-style format (using `\\boxed{...}`) to reliably pinpoint the answer.\n",
        "- **Normalization and Comparison:** Before comparing, both the predicted answer and the ground truth are normalized using several functions. These functions handle different mathematical expressions, such as fractions, matrices, and algebraic expressions, ensuring that the comparison is fair and accurate regardless of formatting differences.\n",
        "- **Evaluation Loop:** For each problem:\n",
        "  - The ground truth answer is extracted from the provided solution.\n",
        "  - A response is generated by the LLM using a designated function.\n",
        "  - The predicted answer is then extracted and compared against the ground truth.\n",
        "  - The results for each problem, including whether the predicted answer is correct, are saved for later analysis.\n",
        "- **Results Analysis:** After processing all problems, the cell aggregates the results and prints a summary, including the total number of problems evaluated, the number of correct answers, and the overall accuracy.\n",
        "\n",
        "This evaluation method ensures that the output of each inference technique (such as Chain-of-Thought, Best-of-n, Beam Search, and Self-Refinement) is consistently measured against the Math Benchmark, without altering the original answers or evaluation logic.\n",
        "\n",
        "**Note:**  \n",
        "\n",
        "🔹 you don't need to modify this cell. Only rewrite the evaluation function portion then\n",
        "\n",
        "🔹 you need to run this cell before evaluating.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jgnyeyBxE2Ci"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from typing import Dict, Optional, Union\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# Load the MATH-500 dataset\n",
        "def load_math500_dataset():\n",
        "    dataset = load_dataset(\"HuggingFaceH4/MATH-500\")[\"test\"]\n",
        "    return dataset\n",
        "\n",
        "# Extract the last boxed answer from text\n",
        "def extract_answer(response: str) -> Optional[str]:\n",
        "    if not response:\n",
        "        return None\n",
        "    start_idx = response.rfind('\\\\boxed{')\n",
        "    if start_idx == -1:\n",
        "        return None\n",
        "    brace_count = 1\n",
        "    pos = start_idx + 7  # length of '\\boxed{'\n",
        "    while pos < len(response) and brace_count > 0:\n",
        "        if response[pos] == '{':\n",
        "            brace_count += 1\n",
        "        elif response[pos] == '}':\n",
        "            brace_count -= 1\n",
        "        pos += 1\n",
        "    if brace_count == 0:\n",
        "        answer = response[start_idx + 7:pos - 1]\n",
        "        return answer.strip()\n",
        "    return None\n",
        "\n",
        "# Normalization and comparison functions (unchanged from original)\n",
        "def normalize_number(num_str: str) -> str:\n",
        "    try:\n",
        "        cleaned = re.sub(r'[,\\$\\\\]|\\s*(?:cm|m|kg|ft|in|lb|oz|ml|L)$|\\s*\\\\text{[^}]+}', '', num_str).strip()\n",
        "        if cleaned.startswith('.'):\n",
        "            cleaned = '0' + cleaned\n",
        "        num = float(cleaned)\n",
        "        if abs(num) < 1 and '.' in cleaned:\n",
        "            decimal_places = len(cleaned.split('.')[1])\n",
        "            format_str = f\"{{:.{decimal_places}f}}\"\n",
        "            result = format_str.format(num)\n",
        "        else:\n",
        "            result = str(num)\n",
        "        return result\n",
        "    except:\n",
        "        return num_str\n",
        "\n",
        "def numerically_equal(str1: str, str2: str) -> bool:\n",
        "    try:\n",
        "        return abs(float(str1) - float(str2)) < 1e-10\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def normalize_fraction(fraction_str: str) -> str:\n",
        "    try:\n",
        "        fraction_str = fraction_str.replace('\\\\dfrac', '\\\\frac')\n",
        "        fraction_str = ''.join(fraction_str.split())\n",
        "        fraction_str = re.sub(r'\\s*\\\\text{[^}]+}', '', fraction_str)\n",
        "        mixed_brace = re.match(r'^\\\\frac(\\d+)\\{(\\d+)\\}$', fraction_str)\n",
        "        if mixed_brace:\n",
        "            num, den = mixed_brace.groups()\n",
        "            return f\"\\\\frac{{{num}}}{{{den}}}\"\n",
        "        no_braces = re.match(r'^\\\\frac(\\d+)(\\d+)$', fraction_str)\n",
        "        if no_braces:\n",
        "            num, den = no_braces.groups()\n",
        "            return f\"\\\\frac{{{num}}}{{{den}}}\"\n",
        "        if '/' in fraction_str and not any(c in fraction_str for c in '\\\\{}'):\n",
        "            num, den = fraction_str.split('/')\n",
        "            return f\"\\\\frac{{{num.strip()}}}{{{den.strip()}}}\"\n",
        "        standard = re.match(r'^\\\\frac\\{([^{}]+)\\}\\{([^{}]+)\\}$', fraction_str)\n",
        "        if standard:\n",
        "            num, den = standard.groups()\n",
        "            return f\"\\\\frac{{{num}}}{{{den}}}\"\n",
        "    except:\n",
        "        return fraction_str\n",
        "\n",
        "def normalize_matrix_entry(entry: str) -> str:\n",
        "    entry = ''.join(entry.split())\n",
        "    if '/' in entry and not any(c in entry for c in '\\\\{}'):\n",
        "        if entry.startswith('-'):\n",
        "            num, den = entry[1:].split('/')\n",
        "            return f\"-{num.strip()}/{den.strip()}\"\n",
        "        else:\n",
        "            num, den = entry.split('/')\n",
        "            return f\"{num.strip()}/{den.strip()}\"\n",
        "    entry = entry.replace('\\\\dfrac', '\\\\frac')\n",
        "    frac_match = re.match(r'^(-)?\\\\frac\\{(\\d+)\\}\\{(\\d+)\\}$', entry)\n",
        "    if frac_match:\n",
        "        sign, num, den = frac_match.groups()\n",
        "        sign = sign if sign else ''\n",
        "        return f\"{sign}{num}/{den}\"\n",
        "    return entry\n",
        "\n",
        "def normalize_matrix(matrix_str: str) -> str:\n",
        "    try:\n",
        "        matrix_str = ''.join(matrix_str.split())\n",
        "        match = re.match(r'^\\\\begin\\{pmatrix\\}(.*?)\\\\end\\{pmatrix\\}$', matrix_str)\n",
        "        if not match:\n",
        "            return matrix_str\n",
        "        content = match.group(1)\n",
        "        rows = content.split('\\\\\\\\')\n",
        "        normalized_rows = []\n",
        "        for row in rows:\n",
        "            if '&' in row:\n",
        "                entries = [normalize_matrix_entry(entry) for entry in row.split('&')]\n",
        "            else:\n",
        "                entries = [normalize_matrix_entry(row)]\n",
        "            normalized_rows.append('&'.join(entries))\n",
        "        result = \"\\\\begin{pmatrix}\" + \"\\\\\\\\\".join(normalized_rows) + \"\\\\end{pmatrix}\"\n",
        "        return result\n",
        "    except:\n",
        "        return matrix_str\n",
        "\n",
        "def normalize_algebraic_expression(expr: str) -> str:\n",
        "    try:\n",
        "        expr = ''.join(expr.split())\n",
        "        monomial_match = re.match(r'^(-?\\d*\\.?\\d*)?([a-zA-Z])(?:\\^(-?\\d+))?$', expr)\n",
        "        if monomial_match:\n",
        "            coeff, var, exp = monomial_match.groups()\n",
        "            coeff = coeff if coeff and coeff not in ['+', '-'] else ('1' if not coeff else '-1')\n",
        "            exp = exp if exp else '1'\n",
        "            if coeff == '1' and exp == '1':\n",
        "                return var\n",
        "            elif coeff == '1':\n",
        "                return f\"{var}^{exp}\"\n",
        "            elif coeff == '-1' and exp == '1':\n",
        "                return f\"-{var}\"\n",
        "            elif coeff == '-1':\n",
        "                return f\"-{var}^{exp}\"\n",
        "            elif exp == '1':\n",
        "                return f\"{coeff}{var}\"\n",
        "            else:\n",
        "                return f\"{coeff}{var}^{exp}\"\n",
        "        pi_term_match = re.match(r'^(-?\\d*\\.?\\d*)\\\\?pi$', expr)\n",
        "        if pi_term_match:\n",
        "            coeff = pi_term_match.group(1)\n",
        "            if not coeff or coeff == '-':\n",
        "                coeff = '-1' if coeff == '-' else '1'\n",
        "            return f\"{coeff}\\\\pi\"\n",
        "        frac_pi_match = re.match(r'^\\\\frac{([^{}]+)}{([^{}]+)}\\\\?pi$', expr)\n",
        "        if frac_pi_match:\n",
        "            num, den = frac_pi_match.groups()\n",
        "            return f\"\\\\frac{{{num}}}{{{den}}}\\\\pi\"\n",
        "        frac_match = re.match(r'^\\\\frac{([^{}]+)}{([^{}]+)}$', expr)\n",
        "        if frac_match:\n",
        "            num, den = frac_match.groups()\n",
        "            return f\"\\\\frac{{{num}}}{{{den}}}\"\n",
        "    except:\n",
        "        return expr.lower()\n",
        "\n",
        "def normalize_interval_bound(bound: str) -> str:\n",
        "    if '\\\\infty' in bound:\n",
        "        sign = '-' if bound.startswith('-') else ''\n",
        "        return f\"{sign}\\\\infty\"\n",
        "    return normalize_answer(bound) or bound\n",
        "\n",
        "def normalize_interval(interval_str: str) -> str:\n",
        "    try:\n",
        "        interval_str = ''.join(interval_str.split())\n",
        "        match = re.match(r'^\\\\left?([\\[\\(])(.*?),(.*?)\\\\right?([\\]\\)])$', interval_str)\n",
        "        if not match:\n",
        "            match = re.match(r'^([\\[\\(])(.*?),(.*?)([\\]\\)])$', interval_str)\n",
        "            if not match:\n",
        "                return interval_str\n",
        "        left_bracket, left_bound, right_bound, right_bracket = match.groups()\n",
        "        norm_left = normalize_interval_bound(left_bound)\n",
        "        norm_right = normalize_interval_bound(right_bound)\n",
        "        return f\"\\\\left{left_bracket}{norm_left},{norm_right}\\\\right{right_bracket}\"\n",
        "    except:\n",
        "        return interval_str\n",
        "\n",
        "def normalize_ordered_tuple(tuple_str: str) -> str:\n",
        "    try:\n",
        "        tuple_str = tuple_str.replace('\\\\dfrac', '\\\\frac')\n",
        "        tuple_str = tuple_str.replace('\\\\left', '').replace('\\\\right', '')\n",
        "        tuple_str = re.sub(r'\\\\?\\s+', '', tuple_str)\n",
        "        inner = tuple_str.strip('()')\n",
        "        parts = inner.split(',')\n",
        "        normalized_parts = [normalize_answer(part.strip()) for part in parts if normalize_answer(part.strip())]\n",
        "        return f\"({','.join(normalized_parts)})\"\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def normalize_answer(answer: str) -> str:\n",
        "    if answer is None:\n",
        "        return \"\"\n",
        "    answer = re.sub(r'\\\\text{[^}]+(?:inches|feet|meters|cm|m|kg|ft|in|lb|oz|ml|L|per|second|minute|hour)[^}]*}', '', answer)\n",
        "    answer = re.sub(r'(?<!\\\\)\\s+', '', answer)\n",
        "    ordered_pair_match = re.match(r'^(?:\\\\left)?\\((.*?)(?:\\\\right)?\\)$', answer)\n",
        "    if ordered_pair_match:\n",
        "        content = ordered_pair_match.group(1)\n",
        "        parts = content.split(',')\n",
        "        normalized_parts = [normalize_answer(part) for part in parts if normalize_answer(part)]\n",
        "        return f\"({','.join(normalized_parts)})\"\n",
        "    answer = ''.join(answer.split())\n",
        "    if not answer:\n",
        "        return None\n",
        "    pm_match = re.match(r'^(.*?)(?:\\\\pm|-)(.*?)$', answer)\n",
        "    if pm_match:\n",
        "        left, right = pm_match.groups()\n",
        "        norm_left = normalize_answer(left) if left else \"\"\n",
        "        norm_right = normalize_answer(right) if right else \"\"\n",
        "        if norm_left or norm_right:\n",
        "            return f\"{norm_left}\\\\pm{norm_right}\"\n",
        "    trig_match = re.match(r'^\\\\(?:sin|cos|tan|cot|sec|csc)\\s*([a-zA-Z])$', answer)\n",
        "    if trig_match:\n",
        "        variable = trig_match.group(1)\n",
        "        func_name = re.match(r'^\\\\(.*?)(?:\\s|$)', answer).group(1)\n",
        "        return f\"\\\\{func_name}{variable}\"\n",
        "    text_match = re.match(r'^(?:\\\\text{)?([A-Za-z]+)(?:})?$', answer)\n",
        "    if text_match:\n",
        "        return text_match.group(1).lower()\n",
        "    if (answer.startswith('\\\\left[') or answer.startswith('\\\\left(') or\n",
        "        answer.startswith('[') or answer.startswith('(')) and \\\n",
        "       (answer.endswith('\\\\right]') or answer.endswith('\\\\right)') or\n",
        "        answer.endswith(']') or answer.endswith(')')):\n",
        "        return normalize_interval(answer)\n",
        "    if answer.startswith('\\\\begin{pmatrix}') and answer.endswith('\\\\end{pmatrix}'):\n",
        "        return normalize_matrix(answer)\n",
        "    answer = answer.replace('\\\\dfrac', '\\\\frac')\n",
        "    if '\\\\frac' in answer or '/' in answer:\n",
        "        return normalize_fraction(answer)\n",
        "    neg_sqrt_match = re.match(r'^-\\\\sqrt\\{?(\\d+)\\}?$', answer)\n",
        "    if neg_sqrt_match:\n",
        "        num = neg_sqrt_match.group(1)\n",
        "        return f\"-\\\\sqrt{{{num}}}\"\n",
        "    sqrt_match = re.match(r'^(\\d*)?\\\\sqrt\\{?(\\d+)\\}?$', answer)\n",
        "    if sqrt_match:\n",
        "        coeff, num = sqrt_match.groups()\n",
        "        coeff = coeff if coeff else '1'\n",
        "        return f\"\\\\sqrt{{{num}}}\" if coeff == '1' else f\"{coeff}\\\\sqrt{{{num}}}\"\n",
        "    sqrt_with_coeff_match = re.match(r'^(\\d+)\\\\sqrt\\{?(\\d+)\\}?$', answer)\n",
        "    if sqrt_with_coeff_match:\n",
        "        coeff, num = sqrt_with_coeff_match.groups()\n",
        "        return f\"{coeff}\\\\sqrt{{{num}}}\"\n",
        "    base_match = re.match(r'^(\\d+)(?:_\\{?(\\d+)\\}?|_(\\d+))$', answer)\n",
        "    if base_match:\n",
        "        number, base1, base2 = base_match.groups()\n",
        "        base = base1 if base1 else base2\n",
        "        return f\"{number}_{base}\"\n",
        "    percent_match = re.match(r'^(\\d+(?:\\.\\d*)?)\\s*\\\\?%$', answer)\n",
        "    if percent_match:\n",
        "        return normalize_number(percent_match.group(1))\n",
        "    unit_match = re.match(r'^(\\d+(?:\\.\\d*)?)\\s*(?:(?:\\\\[,\\s])|,)?\\s*(?:\\\\\\\\)?(?:\\\\text{(\\w+)}|\\\\?(?:cm|m|kg|ft|in|lb|oz|ml|L))$', answer)\n",
        "    if unit_match:\n",
        "        return normalize_number(unit_match.group(1))\n",
        "    currency_match = re.match(r'^\\\\?\\$?([\\d,]+\\.?\\d*)$', answer)\n",
        "    if currency_match:\n",
        "        return normalize_number(currency_match.group(1))\n",
        "    if re.match(r'^-?[\\d,]+$', answer):\n",
        "        return normalize_number(answer)\n",
        "    unit_match = re.match(r'^(-?[\\d,]+(?:\\.\\d*)?)\\s*(?:\\\\(?:mbox|text|hbox|displaystyle)\\{[^}]+\\})?(?:\\^?\\d)?$', answer)\n",
        "    if unit_match:\n",
        "        return normalize_number(unit_match.group(1))\n",
        "    mc_match = re.match(r'^\\\\text{\\(?([A-Za-z])\\)?}$|^\\(?([A-Za-z])\\)?$', answer)\n",
        "    if mc_match:\n",
        "        return (mc_match.group(1) or mc_match.group(2)).lower()\n",
        "    degree_match = re.match(r'^(-?[\\d,]+(?:\\.\\d*)?)\\s*(?:(?:\\^?\\\\circ)|(?:{\\\\circ})|(?:°))?$', answer)\n",
        "    if degree_match:\n",
        "        return normalize_number(degree_match.group(1))\n",
        "    answer = re.sub(r'\\\\text{([^{}]+)}', r'\\1', answer)\n",
        "    try:\n",
        "        return normalize_algebraic_expression(answer)\n",
        "    except:\n",
        "        pass\n",
        "    answer = answer.replace('\\\\left', '').replace('\\\\right', '')\n",
        "    answer = answer.replace('\\\\(', '(').replace('\\\\)', ')')\n",
        "    answer = answer.replace('\\\\[', '[').replace('\\\\]', ']')\n",
        "    answer = answer.replace('\\\\{', '{').replace('\\\\}', '}')\n",
        "    answer = re.sub(r'\\\\sqrt\\{?(\\d+)\\}?', r'\\\\sqrt{\\1}', answer)\n",
        "    answer = re.sub(r'\\\\sqrt{([^{}]+)}', r'\\\\sqrt\\1', answer)\n",
        "    if re.match(r'^\\d+\\\\%$', answer) or re.match(r'^\\d+$', answer):\n",
        "        answer = re.sub(r'\\\\%$', '', answer)\n",
        "    answer = re.sub(r'\\\\text{([^{}]+)}', r'\\1', answer)\n",
        "    while len(answer) >= 2 and answer[0] == '{' and answer[-1] == '}':\n",
        "        if '\\\\frac' in answer:\n",
        "            break\n",
        "        answer = answer[1:-1]\n",
        "    return answer.lower() if answer else None\n",
        "\n",
        "def compare_answers(correct_answer: str, predicted_answer: Optional[str]) -> bool:\n",
        "    if predicted_answer is None:\n",
        "        return False\n",
        "    if numerically_equal(correct_answer, predicted_answer):\n",
        "        return True\n",
        "    normalized_correct = normalize_answer(correct_answer)\n",
        "    normalized_predicted = normalize_answer(predicted_answer)\n",
        "    if not normalized_correct or not normalized_predicted:\n",
        "        return False\n",
        "    if normalized_correct == \"\" and normalized_predicted == \"\":\n",
        "        return False\n",
        "    if ('\\\\left[' in normalized_correct or '\\\\left(' in normalized_correct) and \\\n",
        "       ('\\\\left[' in normalized_predicted or '\\\\left(' in normalized_predicted):\n",
        "        return normalized_correct == normalized_predicted\n",
        "    return normalized_correct == normalized_predicted\n",
        "\n",
        "# Load existing results\n",
        "def load_existing_results(filename: str) -> list[Dict]:\n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "\n",
        "# Save a single result\n",
        "def save_result(filename: str, result: Dict):\n",
        "    results = load_existing_results(filename)\n",
        "    results.append(result)\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "# Analyze and print results\n",
        "def analyze_results(results: list[Dict]):\n",
        "    total = len(results)\n",
        "    correct = sum(1 for r in results if r['is_correct'])\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    print(\"\\n=== Results Summary ===\")\n",
        "    print(f\"Total problems: {total}\")\n",
        "    print(f\"Correct answers: {correct}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(\"\\n=== Incorrect Problems ===\")\n",
        "    for r in results:\n",
        "        if not r['is_correct']:\n",
        "            print(f\"Problem {r['index']}:\")\n",
        "            print(f\"Expected: {r['correct_answer']}\")\n",
        "            print(f\"Predicted: {r['predicted_answer']}\")\n",
        "            print(\"---\")\n",
        "\n",
        "# Main evaluation function\n",
        "def evaluate():\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    results_file = \"evaluation_results_math500_deepseek.json\"\n",
        "    dataset = load_math500_dataset()\n",
        "    existing_results = load_existing_results(results_file)\n",
        "    processed_indexes = {result['index'] for result in existing_results}\n",
        "    cnt = 0\n",
        "    t=0\n",
        "    for idx, item in enumerate(tqdm(dataset, desc=\"Evaluating problems\")):\n",
        "        if idx in processed_indexes:\n",
        "            continue\n",
        "        t += 1\n",
        "        problem_text = item['problem']\n",
        "        correct_answer = extract_answer(item['solution'])  # Extract from 'solution', not 'answer'\n",
        "        response = get_llm_response(problem_text)\n",
        "        predicted_answer = extract_answer(response)\n",
        "        is_correct = compare_answers(correct_answer, predicted_answer)\n",
        "        result = {\n",
        "            \"index\": idx,\n",
        "            \"problem\": problem_text,\n",
        "            \"response\": response,\n",
        "            \"correct_answer\": correct_answer,\n",
        "            \"predicted_answer\": predicted_answer,\n",
        "            \"is_correct\": is_correct\n",
        "        }\n",
        "        save_result(results_file, result)\n",
        "        if is_correct:\n",
        "          cnt += 1\n",
        "        print(f\"cnt :  {cnt} idx: {t}\")\n",
        "    final_results = load_existing_results(results_file)\n",
        "    analyze_results(final_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNUWF2U_HC8g"
      },
      "source": [
        "# Customizable CoT Prompt Template\n",
        "* modify cot prompt then evaluate on math benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXGtl5M89yjw"
      },
      "outputs": [],
      "source": [
        "# final answer should be in this format: (because of extract_answer function you can change it if you want)\n",
        "#\\\\[\n",
        "#\\\\boxed{your_answer_here}\n",
        "#\\\\]\n",
        "\n",
        "COT_PROMPT = \"\"\"Solve the following math problem step by step, clearly explaining your reasoning.\n",
        "At the end, write only the final answer enclosed in LaTeX format as shown:\n",
        "\n",
        "\\\\[\n",
        "\\\\boxed{your_final_answer}\n",
        "\\\\]\n",
        "\n",
        "Make sure the entire answer is inside the \\\\boxed{}.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_EKjMq9yjw"
      },
      "source": [
        "* generate response with cot prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58w5yeo9GrP2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_COT_response(problem):\n",
        "    prompt = COT_PROMPT + \"\\n\" + problem\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "\n",
        "        ],\n",
        "    \"max_tokens\": 1900,\n",
        "    \"temperature\": 0.3\n",
        "    }\n",
        "    response = requests.post(url, json=payload)\n",
        "    return response.json()['choices'][0]['message']['content'].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Una6ucDAHb2_"
      },
      "source": [
        "# Evaluate CoT\n",
        "* modify response generation part to evalute this method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na6kksqZHbOq"
      },
      "outputs": [],
      "source": [
        "def evaluate_cot():\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    results_file = \"evaluation_results_math500_deepseek_cot.json\"\n",
        "    dataset = load_math500_dataset()\n",
        "    existing_results = load_existing_results(results_file)\n",
        "    processed_indexes = {result['index'] for result in existing_results}\n",
        "    cnt = 0\n",
        "    for idx, item in enumerate(tqdm(dataset, desc=\"Evaluating problems\")):\n",
        "        if idx in processed_indexes:\n",
        "            continue\n",
        "        if idx >= 30:\n",
        "          break\n",
        "        problem_text = item['problem']\n",
        "        correct_answer = extract_answer(item['solution'])\n",
        "\n",
        "        # TODO: Generate a response with cot\n",
        "        response = get_COT_response(problem_text)\n",
        "        predicted_answer = extract_answer(response)\n",
        "        ##########################################################\n",
        "        is_correct = compare_answers(correct_answer, predicted_answer)\n",
        "        result = {\n",
        "            \"index\": idx,\n",
        "            \"problem\": problem_text,\n",
        "            \"response\": response,\n",
        "            \"correct_answer\": correct_answer,\n",
        "            \"predicted_answer\": predicted_answer,\n",
        "            \"is_correct\": is_correct\n",
        "        }\n",
        "        save_result(results_file, result)\n",
        "        if is_correct:\n",
        "          cnt += 1\n",
        "        print(f\"corrects :  {cnt} idx: {idx}\")\n",
        "    final_results = load_existing_results(results_file)\n",
        "    analyze_results(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e5672049543d403fa763effa2ac75032",
            "35817d15a3e84eefa7e1883fdf02ec66",
            "6a7650aadec84052aa32288292f280d2",
            "a99c814584414cf58d6bfc1078b03f68",
            "e5f256337399421e87b3ba1f6bf3e1d5",
            "e3a8056efd9c416ca762e8bce9e36363",
            "e147f8a527264645923f548e31b29e56",
            "7f637abfc0f845c5bcb891bca701583b",
            "fd716e363fb9497a8afbd6bfe5acab2e",
            "fbce950cd56142d8832b55cc5d75471d",
            "d1b28b9e2979421481454b4fbb43b698",
            "32a232d8379948e18c5451cf1e105a96",
            "67e792a2cbe14b94985e9a4bfb2dd908",
            "5e84a6b2241b4bd599e2b530c7a22998",
            "1f4bb7c4f5f6491d9be0d3c613e26a16",
            "c1cc394d13fe4fe5ae4b3567faea7047",
            "13763b9f9071419fbafbf6cc503cc12b",
            "a0a2994ed91640ca99818fe2fcca1f80",
            "595b3e78969840e89d36fb66b4689d7d",
            "009d2be74db447b2874d2b5f8613de8e",
            "c9d36a40f9c345199d3c5f778e4e3725",
            "935515f70c5940508b107e99f8f28e7c",
            "12066463cbc14b048843c251586930a5",
            "f67d88767ef249a08f1c144e05fd75c1",
            "9e1dc804e9344baf839699e91b2d1197",
            "00eb67fc1e884b1cafe871252c2fc860",
            "ed6bc8078de3465b87a7f88fe6428170",
            "18eb7562c0eb4eec87be3e3d3e87b360",
            "8ff5895a64e444e7a8f7bbfc654a9d42",
            "a2f6e2076e1745b4b8bf65e1898303e4",
            "5a699a673c9e43e4a158a0e3f2458320",
            "5a9a99b6209f4e1ba13f43a1b82dba94",
            "3af438147c7d4357a48744c234d4daf1"
          ]
        },
        "id": "EJbLqPXYOLvm",
        "outputId": "61709704-8862-47c8-e000-621ffccca061"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5672049543d403fa763effa2ac75032",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/412 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32a232d8379948e18c5451cf1e105a96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.jsonl:   0%|          | 0.00/447k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12066463cbc14b048843c251586930a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   0%|          | 1/500 [00:10<1:28:58, 10.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  1 idx: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   0%|          | 2/500 [00:43<3:18:26, 23.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  1 idx: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 3/500 [00:56<2:36:14, 18.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  2 idx: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 4/500 [01:06<2:06:37, 15.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  3 idx: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 5/500 [01:39<2:58:25, 21.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  3 idx: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 6/500 [01:49<2:26:47, 17.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  4 idx: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|▏         | 7/500 [02:05<2:21:27, 17.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  5 idx: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 8/500 [02:24<2:25:53, 17.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 9/500 [02:37<2:11:46, 16.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 10/500 [03:10<2:54:56, 21.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 11/500 [03:43<3:22:54, 24.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 12/500 [04:16<3:42:06, 27.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 13/500 [04:49<3:55:15, 28.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 14/500 [04:58<3:08:05, 23.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  8 idx: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 15/500 [05:21<3:05:17, 22.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  8 idx: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 16/500 [05:53<3:28:51, 25.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  8 idx: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 17/500 [06:14<3:16:30, 24.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▎         | 18/500 [06:47<3:36:40, 26.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 19/500 [07:20<3:50:22, 28.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 20/500 [07:53<3:59:29, 29.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 21/500 [08:00<3:03:22, 22.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 22/500 [08:32<3:26:26, 25.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 23/500 [08:52<3:10:34, 23.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 24/500 [09:14<3:06:03, 23.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 25/500 [09:41<3:13:37, 24.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 26/500 [10:14<3:32:59, 26.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 27/500 [10:47<3:46:23, 28.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 28/500 [10:58<3:05:25, 23.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 29/500 [11:10<2:37:15, 20.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   6%|▌         | 30/500 [11:26<2:59:08, 22.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  13 idx: 29\n",
            "\n",
            "=== Results Summary ===\n",
            "Total problems: 30\n",
            "Correct answers: 13\n",
            "Accuracy: 43.33%\n",
            "\n",
            "=== Incorrect Problems ===\n",
            "Problem 1:\n",
            "Expected: p - q\n",
            "Predicted: None\n",
            "---\n",
            "Problem 4:\n",
            "Expected: \\text{Evelyn}\n",
            "Predicted: None\n",
            "---\n",
            "Problem 9:\n",
            "Expected: 4\n",
            "Predicted: None\n",
            "---\n",
            "Problem 10:\n",
            "Expected: 2220\n",
            "Predicted: None\n",
            "---\n",
            "Problem 11:\n",
            "Expected: \\frac{3}{56}\n",
            "Predicted: None\n",
            "---\n",
            "Problem 12:\n",
            "Expected: 284\n",
            "Predicted: None\n",
            "---\n",
            "Problem 14:\n",
            "Expected: \\sqrt{51}\n",
            "Predicted: 5\n",
            "---\n",
            "Problem 15:\n",
            "Expected: 6 - 5i\n",
            "Predicted: None\n",
            "---\n",
            "Problem 17:\n",
            "Expected: \\pi\n",
            "Predicted: None\n",
            "---\n",
            "Problem 18:\n",
            "Expected: 28\n",
            "Predicted: None\n",
            "---\n",
            "Problem 19:\n",
            "Expected: 3\n",
            "Predicted: None\n",
            "---\n",
            "Problem 20:\n",
            "Expected: 6+9i\n",
            "Predicted: 6 + 9i\n",
            "---\n",
            "Problem 21:\n",
            "Expected: 13535\n",
            "Predicted: None\n",
            "---\n",
            "Problem 23:\n",
            "Expected: x=5\n",
            "Predicted: 5\n",
            "---\n",
            "Problem 25:\n",
            "Expected: 1,-2\n",
            "Predicted: None\n",
            "---\n",
            "Problem 26:\n",
            "Expected: 144\n",
            "Predicted: None\n",
            "---\n",
            "Problem 28:\n",
            "Expected: -2 + 7i\n",
            "Predicted: -2 + 7i\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_cot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZhLToqU9yjx"
      },
      "source": [
        "## Best-of-N\n",
        "\n",
        "The Best-of-N approach generates several candidate responses for a problem and then selects the one with the highest average token log-likelihood. This ensures that the final answer, formatted within the `\\boxed{}` command, is not only correct in presentation but also statistically the most reliable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1NylbVYkT1kx"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = '''You are solving mathematics problems.\n",
        "\n",
        "Please think step by step.\n",
        "\n",
        "Important: Always end your solution with the final answer in this format:\n",
        "\n",
        "\\\\[\n",
        "\\\\boxed{your_answer_here}\n",
        "\\\\]\n",
        "\n",
        "The entire answer should be contained completely within the \\\\boxed{} command.'''\n",
        "\n",
        "def get_response_logprobs(prompt, max_tokens=1900, temperature=0.3):\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "\n",
        "        ],\n",
        "    \"max_tokens\": max_tokens,\n",
        "    \"temperature\": temperature,\n",
        "    \"logprobs\": True,\n",
        "    }\n",
        "    response = requests.post(url, json=payload)\n",
        "    return response.json()\n",
        "\n",
        "def best_of_n_response(problem, N=5):\n",
        "    best_answer = None\n",
        "    best_avg_likelihood = float('-inf')\n",
        "    best_responses = []\n",
        "    prompt = SYSTEM_PROMPT + \"\\n\" + problem\n",
        "\n",
        "    for t in range(N):\n",
        "        # TODO: Generate a response\n",
        "        response = get_response_logprobs(prompt)\n",
        "        # TODO:  Iterate over each choice in the response and append lobprob of each tocken to token_logprobs (you can see a sample of response to see how to extract the token logprobs)\n",
        "        for choice in response['choices']:\n",
        "            content = choice['message']['content'].strip()\n",
        "            token_logprobs = []\n",
        "            for cnt in choice['logprobs']['content']:\n",
        "                if 'logprob' in cnt:\n",
        "                    token_logprobs.append(cnt['logprob'])\n",
        "            if len(token_logprobs) == 0:\n",
        "                continue\n",
        "            # TODO: Calculate the average log-likelihood and store the response, answer(that is extracted with extract_answer()), and average log-likelihood\n",
        "            avg_likelihood = sum(token_logprobs) / len(token_logprobs)\n",
        "            answer = extract_answer(content)\n",
        "            if answer == None:\n",
        "                continue\n",
        "            best_responses.append((answer, avg_likelihood))\n",
        "\n",
        "\n",
        "    # TODO: Group the responses by the answer (multiple responses can have the same answer)\n",
        "    grouped_responses = {}\n",
        "    for (answer, avg_likelihood) in best_responses:\n",
        "        if answer not in grouped_responses:\n",
        "            grouped_responses[answer] = []\n",
        "        grouped_responses[answer].append(avg_likelihood)\n",
        "\n",
        "    for answer in grouped_responses:\n",
        "        likelihoods = grouped_responses[answer]\n",
        "        grouped_responses[answer] = sum(likelihoods) / len(likelihoods)\n",
        "    # TODO: Find the best answer based on the average likelihood\n",
        "    for (answer, avg_likelihood) in grouped_responses.items():\n",
        "        if avg_likelihood > best_avg_likelihood:\n",
        "            best_avg_likelihood = avg_likelihood\n",
        "            best_answer = answer\n",
        "\n",
        "    return best_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxxqhDeo9yjx"
      },
      "source": [
        "# Evaluate best of n\n",
        "\n",
        "* modify response generation part to evalute this method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyCkE9ToOHNO"
      },
      "outputs": [],
      "source": [
        "def evaluate_best_of_n():\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    results_file = \"evaluation_results_math500_deepseek_best_of_n.json\"\n",
        "    dataset = load_math500_dataset()\n",
        "    existing_results = load_existing_results(results_file)\n",
        "    processed_indexes = {result['index'] for result in existing_results}\n",
        "    cnt = 0\n",
        "    for idx, item in enumerate(tqdm(dataset, desc=\"Evaluating problems\")):\n",
        "        if idx in processed_indexes:\n",
        "            continue\n",
        "        if idx >= 30:\n",
        "          break\n",
        "        problem_text = item['problem']\n",
        "        correct_answer = extract_answer(item['solution'])\n",
        "        # TODO: ##########################################################\n",
        "        response = best_of_n_response(problem_text)\n",
        "        predicted_answer = response\n",
        "        ##########################################################\n",
        "        is_correct = compare_answers(correct_answer, predicted_answer)\n",
        "        result = {\n",
        "            \"index\": idx,\n",
        "            \"problem\": problem_text,\n",
        "            \"response\": response,\n",
        "            \"correct_answer\": correct_answer,\n",
        "            \"predicted_answer\": predicted_answer,\n",
        "            \"is_correct\": is_correct\n",
        "        }\n",
        "        save_result(results_file, result)\n",
        "        if is_correct:\n",
        "          cnt += 1\n",
        "        print(f\"corrects :  {cnt} idx: {idx}\")\n",
        "    final_results = load_existing_results(results_file)\n",
        "    analyze_results(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "15a71f6880c048a8aa1981074334a86d",
            "ab29e4e2d4e04ca8b2dc828b11df076d",
            "7dcf735613f44ebd8d61fd96a1df133f",
            "f02796974bbe45c3a6998ebdf35d025c",
            "1721df4724e4468cbbe79768b461fbb5",
            "3112d369e376465d83b2d31f1d95ea20",
            "5af6779722a44597a337fb270501c253",
            "e18a3ec0f0ae4748a55a404575184ead",
            "a1869b6b4e5d45149def98c6cf21a303",
            "595cb8ff681b476d8f9732f2de5b707a",
            "4f081aa287a84f79b4b21873bce74d24",
            "5ad697bf784e4343a71ed4a8429d5680",
            "634c44ae7fd34b80869fb357d53df800",
            "4acf3ac9c4904f22881b819394901a84",
            "73400c4522194cd293b94fb5614a9c38",
            "a0e78ba61d494bbf82bba5fc055c81b3",
            "e3604a3bb4244b49a580688bd61d25ef",
            "fb77790ad7914a32acf446e29d4e33f3",
            "25ff824b5e98433ab70192475e67e484",
            "07a5e2ad865a4438a33b5c2ad7dcc12b",
            "ff658e1d52324fcf9596c1ddce033527",
            "ff3ac586a9874232bda30c66dbbca79f",
            "e990b721c0ab42ef99c16e71ded08485",
            "c772d846930646cdba6a5eca507ee6b0",
            "1e4615cbaab246e89b083b4d7d10ff31",
            "2f1ffeed60f84b43bb96dcd5985292fb",
            "1cbac43a26a6433daaab1d3a3dcc0cdf",
            "eb47df580dd9476baac2a2d306fd81a5",
            "70d9911202474136939d36c1a32b6f4c",
            "2eed85eeca14493d89a528aa04672528",
            "9b025a53cf3f496a8c7750709e37c2a8",
            "272ba961dd654328bc1c421ccecf4f10",
            "23e3b6f8b2554ed9b62befe0dc9e9965"
          ]
        },
        "id": "W_6D_Pb8V3tr",
        "outputId": "4de7b2f1-85cd-4497-abc9-0eeb83122612"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15a71f6880c048a8aa1981074334a86d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/412 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ad697bf784e4343a71ed4a8429d5680",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.jsonl:   0%|          | 0.00/447k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e990b721c0ab42ef99c16e71ded08485",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   0%|          | 1/500 [00:57<7:54:56, 57.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  1 idx: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   0%|          | 2/500 [03:44<16:52:23, 121.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  1 idx: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 3/500 [04:43<12:51:02, 93.08s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  2 idx: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 4/500 [05:27<10:11:21, 73.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  3 idx: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 5/500 [06:45<10:21:27, 75.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  3 idx: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 6/500 [07:23<8:35:30, 62.61s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  3 idx: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|▏         | 7/500 [10:13<13:21:48, 97.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  4 idx: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 8/500 [13:01<16:25:29, 120.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  5 idx: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 9/500 [14:04<13:57:41, 102.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 10/500 [16:55<16:47:59, 123.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 11/500 [18:13<14:53:50, 109.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 12/500 [21:02<17:17:23, 127.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 13/500 [21:53<14:07:40, 104.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 14/500 [22:24<11:04:49, 82.08s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 15/500 [24:52<13:46:08, 102.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  8 idx: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 16/500 [27:44<16:34:08, 123.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 17/500 [28:52<14:18:13, 106.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▎         | 18/500 [31:45<16:56:13, 126.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 19/500 [34:35<18:38:47, 139.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 20/500 [37:23<19:43:09, 147.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 21/500 [37:47<14:44:01, 110.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 22/500 [40:34<16:56:40, 127.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 23/500 [43:21<18:28:20, 139.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 24/500 [45:16<17:29:24, 132.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 25/500 [46:38<15:28:25, 117.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 26/500 [49:25<17:23:14, 132.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 27/500 [52:11<18:42:17, 142.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 28/500 [52:59<14:55:21, 113.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  13 idx: 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 29/500 [55:08<15:30:38, 118.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  13 idx: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   6%|▌         | 30/500 [55:51<14:35:10, 111.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  14 idx: 29\n",
            "\n",
            "=== Results Summary ===\n",
            "Total problems: 30\n",
            "Correct answers: 14\n",
            "Accuracy: 46.67%\n",
            "\n",
            "=== Incorrect Problems ===\n",
            "Problem 1:\n",
            "Expected: p - q\n",
            "Predicted: None\n",
            "---\n",
            "Problem 4:\n",
            "Expected: \\text{Evelyn}\n",
            "Predicted: 1\n",
            "---\n",
            "Problem 5:\n",
            "Expected: 42\n",
            "Predicted: 42\\ \\text{inches}\n",
            "---\n",
            "Problem 9:\n",
            "Expected: 4\n",
            "Predicted: None\n",
            "---\n",
            "Problem 10:\n",
            "Expected: 2220\n",
            "Predicted: 222\n",
            "---\n",
            "Problem 11:\n",
            "Expected: \\frac{3}{56}\n",
            "Predicted: None\n",
            "---\n",
            "Problem 12:\n",
            "Expected: 284\n",
            "Predicted: 286\n",
            "---\n",
            "Problem 17:\n",
            "Expected: \\pi\n",
            "Predicted: \\frac{\\pi}{3}\n",
            "---\n",
            "Problem 18:\n",
            "Expected: 28\n",
            "Predicted: None\n",
            "---\n",
            "Problem 19:\n",
            "Expected: 3\n",
            "Predicted: None\n",
            "---\n",
            "Problem 20:\n",
            "Expected: 6+9i\n",
            "Predicted: 6 + 9i\n",
            "---\n",
            "Problem 21:\n",
            "Expected: 13535\n",
            "Predicted: None\n",
            "---\n",
            "Problem 23:\n",
            "Expected: x=5\n",
            "Predicted: 5\n",
            "---\n",
            "Problem 25:\n",
            "Expected: 1,-2\n",
            "Predicted: None\n",
            "---\n",
            "Problem 26:\n",
            "Expected: 144\n",
            "Predicted: None\n",
            "---\n",
            "Problem 28:\n",
            "Expected: -2 + 7i\n",
            "Predicted: -2 + 7i\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_best_of_n()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqijXIcG9yjx"
      },
      "source": [
        "## Beam Search\n",
        "\n",
        "This cell implements a beam search strategy for generating candidate reasoning chains. The method generates multiple continuations at each reasoning step, scoring each candidate based on its average token log-likelihood. By retaining and expanding only the top candidates, the approach efficiently searches for the most promising chain-of-thought that leads to the final answer in the required format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2ZQr1A0WBD0"
      },
      "outputs": [],
      "source": [
        "def call_qwen_model_raw(prompt,step_num, temperature=0.6):\n",
        "    \"\"\"\n",
        "    Sends a request to the local Qwen endpoint and returns the generated text\n",
        "    along with the average token log-probability.\n",
        "    \"\"\"\n",
        "    # Build the prompt. We assume the sample already contains the SYSTEM_PROMPT. you can modify max_tokens for different steps\n",
        "    max_tokens = [500, 1000, 1500, 2000]\n",
        "\n",
        "    # TODO: Send a request to the Qwen model and get the response\n",
        "    response = get_response_logprobs(prompt, max_tokens[step_num], temperature=temperature)\n",
        "\n",
        "    # TODO:  Iterate over each choice in the response and append lobprob of each tocken to token_logprobs\n",
        "    token_logprobs = []\n",
        "\n",
        "    choice = response['choices'][0]\n",
        "    output_text = choice['message']['content'].strip()\n",
        "    token_logprobs = []\n",
        "    for cnt in choice['logprobs']['content']:\n",
        "        if 'logprob' in cnt:\n",
        "            token_logprobs.append(cnt['logprob'])\n",
        "\n",
        "    # TODO: Calculate the average log-likelihood\n",
        "\n",
        "    avg_token_prob = sum(token_logprobs) / len(token_logprobs)\n",
        "\n",
        "    return output_text, avg_token_prob, len(token_logprobs)\n",
        "\n",
        "\n",
        "\n",
        "class BeamCandidate:\n",
        "    def __init__(self, sequence, cumulative_log_prob, step_scores, finished=False,num_token = 0):\n",
        "        self.sequence = sequence\n",
        "        self.cumulative_log_prob = cumulative_log_prob\n",
        "        self.step_scores = step_scores\n",
        "        self.finished = finished\n",
        "        self.num_token = num_token\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"BeamCandidate(score={self.cumulative_log_prob:.3f}, finished={self.finished}, \"\n",
        "                f\"sequence={self.sequence})\")\n",
        "\n",
        "\n",
        "\n",
        "def generate_reasoning_steps(context, step_num, top_k):\n",
        "    \"\"\"\n",
        "    For a given candidate reasoning chain (context), generate top_k candidate continuations\n",
        "    for the current reasoning step (from 1 to 5). Each candidate is verified using the average\n",
        "    token logprob as a proxy for quality.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: each step should have a different prompt and the prompt should be added to the context so make a prompt for each step that explains what the step is about\n",
        "    candidates = []\n",
        "    for i in range(top_k):\n",
        "        if step_num == 1:\n",
        "            candidate_prompt = context + \"\\n\" + \"For the 1st step, you should understand what the problem wants, and specify its objectives.\"\n",
        "        if step_num == 2:\n",
        "            candidate_prompt = context + \"\\n\" + \"For the 2nd step, you should think and plan how you want to solve the problem (by reasoning).\"\n",
        "        if step_num == 3:\n",
        "            candidate_prompt = context + \"\\n\" + \"For the 3rd and last step, you should fully solve the problem.\"\n",
        "\n",
        "        # TODO: call the qwen model to get the output and avg_token_prob\n",
        "        candidate_step, avg_token_prob, num_token = call_qwen_model_raw(candidate_prompt, step_num)\n",
        "        finished = True if \"\\\\boxed\" in candidate_step else False\n",
        "        candidates.append((candidate_step, avg_token_prob, num_token, finished))\n",
        "\n",
        "    return candidates\n",
        "\n",
        "def beam_search(init_problem_prompt, beam_width=3, max_steps=3, top_k=2):\n",
        "    \"\"\"\n",
        "    Implements a beam search over reasoning steps.\n",
        "    \"\"\"\n",
        "    prompt = init_problem_prompt\n",
        "    initial_candidate = BeamCandidate(sequence=init_problem_prompt, cumulative_log_prob=0, step_scores=[])\n",
        "    beams = [initial_candidate]\n",
        "\n",
        "    for step_num in range(1, max_steps+1):\n",
        "        new_beams = []\n",
        "\n",
        "        for candidate in beams:\n",
        "            if candidate.finished:\n",
        "                # TODO: Propagate finished candidates unchanged.\n",
        "                new_beams.append(candidate)\n",
        "                continue\n",
        "            step_candidates = generate_reasoning_steps(candidate.sequence, step_num, top_k)\n",
        "            for (step_text, score, num_token, finished) in step_candidates:\n",
        "                # TODO: Create a new candidate by appending the step text to the current sequence and updating the log-probability by averaging all token_logprobs after the new step.\n",
        "                new_candidate = candidate.sequence + \"\\n\" + step_text\n",
        "                new_logprob = (candidate.cumulative_log_prob * candidate.num_token + score * num_token) / (candidate.num_token + num_token)\n",
        "                new_scores = candidate.step_scores + [score]\n",
        "                new_beams.append(BeamCandidate(new_candidate, new_logprob, new_scores, finished, candidate.num_token + num_token))\n",
        "\n",
        "        if not new_beams:\n",
        "            break\n",
        "        # TODO: sort the new beams based on the cumulative_log_prob and put the top beam_width beams in the beams list\n",
        "        beams = sorted(new_beams, key=lambda x: x.cumulative_log_prob, reverse=True)\n",
        "        beams = beams[:beam_width]\n",
        "\n",
        "        if all(beam.finished for beam in beams):\n",
        "            break\n",
        "    # TODO: Get the best candidate from the beams list that is finished\n",
        "    finished_beams = [b for b in beams if b.finished]\n",
        "\n",
        "    best_candidate = max(finished_beams, key=lambda x: x.cumulative_log_prob) if finished_beams else beams[0]\n",
        "    return best_candidate\n",
        "\n",
        "def run_qwen_beam_search(problem, beam_width, max_steps, top_k, log_level):\n",
        "    \"\"\"\n",
        "    sets up the sample prompt, performs beam search,\n",
        "    and extracts the final answer.\n",
        "    \"\"\"\n",
        "    # TODO: Set the initial prompt to the problem and run the beam search to get the best candidate\n",
        "\n",
        "    initial_prompt = SYSTEM_PROMPT + \"\\n\" + problem\n",
        "    best_candidate = beam_search(initial_prompt, beam_width, max_steps, top_k)\n",
        "    final_answer = extract_answer(best_candidate.sequence) if best_candidate.finished else None\n",
        "\n",
        "    return final_answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1uUuVrY9yjx"
      },
      "source": [
        "# Evaluate beam search\n",
        "* modify response generation part to evalute this method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR_TyvGMazTc"
      },
      "outputs": [],
      "source": [
        "def evaluate_beam_search():\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    results_file = \"evaluation_results_math500_deepseek_beam_search.json\"\n",
        "    dataset = load_math500_dataset()\n",
        "    existing_results = load_existing_results(results_file)\n",
        "    processed_indexes = {result['index'] for result in existing_results}\n",
        "    cnt = 0\n",
        "    for idx, item in enumerate(tqdm(dataset, desc=\"Evaluating problems\")):\n",
        "        if idx in processed_indexes :\n",
        "            continue\n",
        "        if idx >= 30:\n",
        "          break\n",
        "        problem_text = item['problem']\n",
        "        correct_answer = extract_answer(item['solution'])\n",
        "        ##########################################################\n",
        "        # TODO: Generate a response with beam search\n",
        "        response = run_qwen_beam_search(problem_text, 3, 3, 2, \"\")\n",
        "        predicted_answer = response\n",
        "        ##########################################################\n",
        "        is_correct = compare_answers(correct_answer, predicted_answer)\n",
        "        result = {\n",
        "            \"index\": idx,\n",
        "            \"problem\": problem_text,\n",
        "            \"response\": response,\n",
        "            \"correct_answer\": correct_answer,\n",
        "            \"predicted_answer\": predicted_answer,\n",
        "            \"is_correct\": is_correct\n",
        "        }\n",
        "        save_result(results_file, result)\n",
        "        if is_correct:\n",
        "          cnt += 1\n",
        "        print(f\"corrects :  {cnt} idx: {idx}\")\n",
        "    final_results = load_existing_results(results_file)\n",
        "    analyze_results(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4fd051c316334259b273142257600b06",
            "9072b751865145b9a2a505e3fa39d9f2",
            "6b35e1244aa9427098567bcca63d3130",
            "a6778c34deca4da69e1c9f4a51718bea",
            "3a677f78e9e94e0aaec34ce4c2fe6eae",
            "5778820fe0824efdb9b5e25341cba6a2",
            "09d6335dd8a54ca49c4a763d47a2d7f3",
            "5c8136ef087041f1890cca6b1baf2830",
            "9f0ed7fd15d94318a003dd5b713ac0f0",
            "cdc9ccf8408649fe878ce8d43fe709e2",
            "97dd122e0d6c43ddb0ac572d0cf4ea50",
            "f1c0507bfbb347a99758b5fc45520b5e",
            "6a68e62ccd07428298385d21a37e3a84",
            "b42309d21e594a239f56fa73672d12ef",
            "4118097744b8444490e87a085fd06527",
            "ab99e55827a540be871c1f28c873e57e",
            "d6c1a01dfd894445bca9d77270d68d91",
            "4ffad2a8aa934fea9bf61a745c4f970f",
            "369447a646d94ae2a4e4e8254f3da18d",
            "ee6aa96ce57041b7b63ac2d7f10052f1",
            "578aa4c9063041e09f30d93df95a3acf",
            "1e0c6a76b58f428b99ad438bd29adb6b",
            "2370176a0bb3478d908536e6dd494ef3",
            "5b9da1a406ba4e4bbe5931c613dd46fa",
            "1287d9dafc6442248785ce19336fe1c7",
            "0bbe8e0b088944c4a0e12c1ab19aa346",
            "bd858f4659684677832751f978d826fa",
            "81b0d76f2d054c18b7c13fc94956a489",
            "f8b286c4b1cd48a89baf9e341d26e2fb",
            "e230f8df0f274a69a25456f56797150b",
            "073bf33202594f16a9ce8717cafe8cc1",
            "fef6254a547b4d0cbc55103db2b0ca59",
            "0f14bc3aca5140d3ba476453b5291499"
          ]
        },
        "id": "sxMjVBf6bpiy",
        "outputId": "84b7a5b6-7767-4ce8-e673-18193aaf53d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fd051c316334259b273142257600b06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/412 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1c0507bfbb347a99758b5fc45520b5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.jsonl:   0%|          | 0.00/447k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2370176a0bb3478d908536e6dd494ef3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   0%|          | 1/500 [00:31<4:23:05, 31.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  1 idx: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   0%|          | 2/500 [03:34<16:39:14, 120.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  2 idx: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 3/500 [03:56<10:27:28, 75.75s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  3 idx: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 4/500 [04:36<8:29:51, 61.68s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  4 idx: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 5/500 [05:50<9:05:01, 66.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  5 idx: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 6/500 [06:15<7:08:42, 52.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|▏         | 7/500 [07:25<7:54:28, 57.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 8/500 [09:36<11:05:33, 81.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  8 idx: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 9/500 [10:09<9:00:48, 66.09s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 10/500 [15:56<20:47:15, 152.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 11/500 [16:19<15:21:41, 113.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 12/500 [22:05<24:57:49, 184.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 13/500 [22:31<18:24:16, 136.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 14/500 [22:44<13:20:15, 98.80s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 15/500 [24:28<13:31:47, 100.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 16/500 [28:34<19:24:26, 144.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  13 idx: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 17/500 [29:38<16:08:14, 120.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  14 idx: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▎         | 18/500 [30:13<12:38:47, 94.45s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  14 idx: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 19/500 [34:00<17:57:08, 134.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  14 idx: 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 20/500 [39:23<25:28:21, 191.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  15 idx: 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 21/500 [40:26<20:17:11, 152.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  15 idx: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 22/500 [46:15<28:04:23, 211.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  16 idx: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 23/500 [51:28<32:04:19, 242.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  17 idx: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 24/500 [51:56<23:30:25, 177.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  17 idx: 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 25/500 [52:22<17:27:29, 132.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  17 idx: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 26/500 [55:32<19:40:38, 149.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  17 idx: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 27/500 [1:01:14<27:13:38, 207.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  17 idx: 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 28/500 [1:01:33<19:47:10, 150.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  18 idx: 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 29/500 [1:02:56<17:03:04, 130.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  18 idx: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   6%|▌         | 30/500 [1:03:15<16:31:08, 126.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  19 idx: 29\n",
            "\n",
            "=== Results Summary ===\n",
            "Total problems: 30\n",
            "Correct answers: 19\n",
            "Accuracy: 63.33%\n",
            "\n",
            "=== Incorrect Problems ===\n",
            "Problem 9:\n",
            "Expected: 4\n",
            "Predicted: None\n",
            "---\n",
            "Problem 11:\n",
            "Expected: \\frac{3}{56}\n",
            "Predicted: \\dfrac{1}{9}\n",
            "---\n",
            "Problem 12:\n",
            "Expected: 284\n",
            "Predicted: 260\n",
            "---\n",
            "Problem 17:\n",
            "Expected: \\pi\n",
            "Predicted: \n",
            "---\n",
            "Problem 18:\n",
            "Expected: 28\n",
            "Predicted: \n",
            "---\n",
            "Problem 20:\n",
            "Expected: 6+9i\n",
            "Predicted: 6 + 9i\n",
            "---\n",
            "Problem 23:\n",
            "Expected: x=5\n",
            "Predicted: 5\n",
            "---\n",
            "Problem 24:\n",
            "Expected: 10\n",
            "Predicted: 49\n",
            "---\n",
            "Problem 25:\n",
            "Expected: 1,-2\n",
            "Predicted: 1\n",
            "---\n",
            "Problem 26:\n",
            "Expected: 144\n",
            "Predicted: None\n",
            "---\n",
            "Problem 28:\n",
            "Expected: -2 + 7i\n",
            "Predicted: -2 + 7i\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_beam_search()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-McTZOk9yjx"
      },
      "source": [
        "## Self-Refinement\n",
        "\n",
        "This approach begins by generating an initial solution using the given prompt. It then iteratively refines this output by providing the model with targeted feedback and asking it to improve its response. The process continues until the feedback indicates that no further refinement is necessary, ensuring that the final answer—properly formatted within the `\\boxed{}` command—is as accurate and well-reasoned as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fAYp7rCbiJQa"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = '''You are solving mathematics problems.\n",
        "\n",
        "Please think step by step.\n",
        "\n",
        "Important: Always end your solution with the final answer in this format:\n",
        "\n",
        "\\\\[\n",
        "\\\\boxed{your_answer_here}\n",
        "\\\\]\n",
        "\n",
        "The entire answer should be contained completely within the \\\\boxed{} command.'''\n",
        "\n",
        "def generate_content(prompt):\n",
        "    # TODO: Send a request to the Qwen model and get the response\n",
        "\n",
        "    response = get_response_logprobs(prompt, max_tokens=2200)\n",
        "    output_text = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "    return output_text\n",
        "\n",
        "def self_refine(problem, max_iter=2):\n",
        "\n",
        "    prompt = SYSTEM_PROMPT + \"\\n\" + problem\n",
        "\n",
        "    # TODO: Generate the initial output using generate_content with the full prompt.\n",
        "    current_output = generate_content(prompt)\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        # TODO: Provide a feedback prompt that asks the model to analyze current_output.\n",
        "        #       - Include both the original prompt and the current output\n",
        "        #       - speicfy the format if the feedback is needed so you can parse it later\n",
        "        feedback_prompt = f'''\n",
        "        You are an expert math reviewer.\n",
        "\n",
        "        You will be shown a math problem and a solution. Your job is to analyze the solution, find any mistakes, and decide if the answer should be refined.\n",
        "\n",
        "        Respond in the following format:\n",
        "\n",
        "        Needs refinement: <yes/no>\n",
        "\n",
        "        Justification:\n",
        "        <your explanation here>\n",
        "\n",
        "        ---\n",
        "\n",
        "        Problem:\n",
        "        {prompt}\n",
        "\n",
        "        Proposed Solution:\n",
        "        {current_output}\n",
        "        '''\n",
        "        feedback_output = generate_content(feedback_prompt)\n",
        "\n",
        "        # TODO: Parse the feedback response to determine if refinement is needed.\n",
        "        parsed = re.search(r\"Needs refinement:\\s*(yes|no)\", feedback_output, re.IGNORECASE)\n",
        "        if parsed is None:\n",
        "            break\n",
        "\n",
        "        refinement_needed = parsed and parsed.group(1).strip().lower() == \"yes\"\n",
        "\n",
        "        if not refinement_needed:\n",
        "            break\n",
        "\n",
        "        # TODO: If refinement is needed:\n",
        "        #       - Create a refine prompt that includes the original prompt, current output, and the feedback.\n",
        "        #       - Send this refine prompt to the model using generate_content to obtain a refined output.\n",
        "        #       - Update current_output with the refined output.\n",
        "        refinement_prompt = f'''\n",
        "        You previously answered the following math problem:\n",
        "        Problem:\n",
        "        {prompt}\n",
        "\n",
        "        Your previous solution was:\n",
        "        {current_output}\n",
        "\n",
        "        A reviewer provided the following feedback:\n",
        "        {feedback_output}\n",
        "\n",
        "        Please revise your solution accordingly. Be sure to end with the final answer in this format:\n",
        "\n",
        "        \\\\[\n",
        "        \\\\boxed{{your_answer_here}}\n",
        "        \\\\]\n",
        "        '''\n",
        "        refined_output = generate_content(refinement_prompt)\n",
        "        if refined_output.strip() == current_output.strip():\n",
        "            break\n",
        "        current_output = refined_output\n",
        "\n",
        "    # TODO: Extract the final answer from current_output (e.g., using an extract_answer function).\n",
        "    answer = extract_answer(current_output)\n",
        "    return answer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGE7neMN9yjx"
      },
      "source": [
        "# Evaluate Self-Refinement\n",
        "* modify response generation part to evalute this method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ln5I9pg_jN7Z"
      },
      "outputs": [],
      "source": [
        "def evaluate_self_refiner():\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    results_file = \"evaluation_results_math500_deepseek_self_refiner.json\"\n",
        "    dataset = load_math500_dataset()\n",
        "    existing_results = load_existing_results(results_file)\n",
        "    processed_indexes = {result['index'] for result in existing_results}\n",
        "    cnt = 0\n",
        "    for idx, item in enumerate(tqdm(dataset, desc=\"Evaluating problems\")):\n",
        "        if idx in processed_indexes :\n",
        "            continue\n",
        "        if idx >= 30:\n",
        "          break\n",
        "        problem_text = item['problem']\n",
        "        correct_answer = extract_answer(item['solution'])\n",
        "        ##########################################################\n",
        "        # TODO: Generate a response with self_refine\n",
        "        response = self_refine(problem_text, 4)\n",
        "        predicted_answer = response\n",
        "        ##########################################################\n",
        "        is_correct = compare_answers(correct_answer, predicted_answer)\n",
        "        result = {\n",
        "            \"index\": idx,\n",
        "            \"problem\": problem_text,\n",
        "            \"response\": response,\n",
        "            \"correct_answer\": correct_answer,\n",
        "            \"predicted_answer\": predicted_answer,\n",
        "            \"is_correct\": is_correct\n",
        "        }\n",
        "        save_result(results_file, result)\n",
        "        if is_correct:\n",
        "          cnt += 1\n",
        "        print(f\"corrects :  {cnt} idx: {idx}\")\n",
        "    final_results = load_existing_results(results_file)\n",
        "    analyze_results(final_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNAg9wa9jlSu",
        "outputId": "beebba76-ab6a-40cc-e665-6a1ab60f2cfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   0%|          | 2/500 [01:17<5:21:23, 38.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  0 idx: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 3/500 [01:40<4:25:35, 32.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  1 idx: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 4/500 [01:57<3:40:59, 26.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  2 idx: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 5/500 [02:22<3:34:16, 25.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  2 idx: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|          | 6/500 [02:34<2:54:45, 21.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  3 idx: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   1%|▏         | 7/500 [03:04<3:18:56, 24.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  4 idx: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 8/500 [03:58<4:35:48, 33.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  5 idx: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 9/500 [04:27<4:21:38, 31.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 10/500 [05:44<6:15:34, 45.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  6 idx: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 11/500 [06:16<5:40:16, 41.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   2%|▏         | 12/500 [07:34<7:07:36, 52.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 13/500 [08:22<6:56:46, 51.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  7 idx: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 14/500 [08:33<5:17:53, 39.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  8 idx: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 15/500 [09:15<5:22:14, 39.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 16/500 [10:15<6:12:04, 46.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  9 idx: 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   3%|▎         | 17/500 [10:34<5:03:35, 37.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▎         | 18/500 [11:31<5:50:04, 43.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 19/500 [12:48<7:10:32, 53.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 20/500 [14:05<8:06:18, 60.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 21/500 [14:16<6:05:30, 45.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   4%|▍         | 22/500 [15:18<6:41:53, 50.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 23/500 [16:35<7:45:43, 58.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▍         | 24/500 [16:58<6:19:15, 47.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  10 idx: 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 25/500 [17:19<5:15:38, 39.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 26/500 [18:07<5:34:32, 42.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   5%|▌         | 27/500 [19:25<6:56:41, 52.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  11 idx: 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 28/500 [19:43<5:35:32, 42.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEvaluating problems:   6%|▌         | 29/500 [20:17<5:13:29, 39.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  12 idx: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating problems:   6%|▌         | 30/500 [20:36<5:22:47, 41.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrects :  13 idx: 29\n",
            "\n",
            "=== Results Summary ===\n",
            "Total problems: 30\n",
            "Correct answers: 14\n",
            "Accuracy: 46.67%\n",
            "\n",
            "=== Incorrect Problems ===\n",
            "Problem 1:\n",
            "Expected: p - q\n",
            "Predicted: None\n",
            "---\n",
            "Problem 4:\n",
            "Expected: \\text{Evelyn}\n",
            "Predicted: 3.6 \\text{ km/h}\n",
            "---\n",
            "Problem 9:\n",
            "Expected: 4\n",
            "Predicted: None\n",
            "---\n",
            "Problem 11:\n",
            "Expected: \\frac{3}{56}\n",
            "Predicted: None\n",
            "---\n",
            "Problem 12:\n",
            "Expected: 284\n",
            "Predicted: 286\n",
            "---\n",
            "Problem 15:\n",
            "Expected: 6 - 5i\n",
            "Predicted: None\n",
            "---\n",
            "Problem 17:\n",
            "Expected: \\pi\n",
            "Predicted: \n",
            "---\n",
            "Problem 18:\n",
            "Expected: 28\n",
            "Predicted: \n",
            "---\n",
            "Problem 19:\n",
            "Expected: 3\n",
            "Predicted: None\n",
            "---\n",
            "Problem 20:\n",
            "Expected: 6+9i\n",
            "Predicted: 6 + 9i\n",
            "---\n",
            "Problem 21:\n",
            "Expected: 13535\n",
            "Predicted: None\n",
            "---\n",
            "Problem 22:\n",
            "Expected: 5\n",
            "Predicted: None\n",
            "---\n",
            "Problem 23:\n",
            "Expected: x=5\n",
            "Predicted: 5\n",
            "---\n",
            "Problem 25:\n",
            "Expected: 1,-2\n",
            "Predicted: None\n",
            "---\n",
            "Problem 26:\n",
            "Expected: 144\n",
            "Predicted: None\n",
            "---\n",
            "Problem 28:\n",
            "Expected: -2 + 7i\n",
            "Predicted: -2 + 7i\n",
            "---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_self_refiner()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color='red'>\n",
        "\n",
        "## MAKE SURE TO READ THE FIRST MARKDOWN CELL! :D"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009d2be74db447b2874d2b5f8613de8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00eb67fc1e884b1cafe871252c2fc860": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a9a99b6209f4e1ba13f43a1b82dba94",
            "placeholder": "​",
            "style": "IPY_MODEL_3af438147c7d4357a48744c234d4daf1",
            "value": " 500/500 [00:00&lt;00:00, 9352.89 examples/s]"
          }
        },
        "073bf33202594f16a9ce8717cafe8cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07a5e2ad865a4438a33b5c2ad7dcc12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d6335dd8a54ca49c4a763d47a2d7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbe8e0b088944c4a0e12c1ab19aa346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef6254a547b4d0cbc55103db2b0ca59",
            "placeholder": "​",
            "style": "IPY_MODEL_0f14bc3aca5140d3ba476453b5291499",
            "value": " 500/500 [00:00&lt;00:00, 6610.05 examples/s]"
          }
        },
        "0f14bc3aca5140d3ba476453b5291499": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12066463cbc14b048843c251586930a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f67d88767ef249a08f1c144e05fd75c1",
              "IPY_MODEL_9e1dc804e9344baf839699e91b2d1197",
              "IPY_MODEL_00eb67fc1e884b1cafe871252c2fc860"
            ],
            "layout": "IPY_MODEL_ed6bc8078de3465b87a7f88fe6428170"
          }
        },
        "1287d9dafc6442248785ce19336fe1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e230f8df0f274a69a25456f56797150b",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_073bf33202594f16a9ce8717cafe8cc1",
            "value": 500
          }
        },
        "13763b9f9071419fbafbf6cc503cc12b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a71f6880c048a8aa1981074334a86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab29e4e2d4e04ca8b2dc828b11df076d",
              "IPY_MODEL_7dcf735613f44ebd8d61fd96a1df133f",
              "IPY_MODEL_f02796974bbe45c3a6998ebdf35d025c"
            ],
            "layout": "IPY_MODEL_1721df4724e4468cbbe79768b461fbb5"
          }
        },
        "1721df4724e4468cbbe79768b461fbb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18eb7562c0eb4eec87be3e3d3e87b360": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cbac43a26a6433daaab1d3a3dcc0cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e0c6a76b58f428b99ad438bd29adb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4615cbaab246e89b083b4d7d10ff31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eed85eeca14493d89a528aa04672528",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b025a53cf3f496a8c7750709e37c2a8",
            "value": 500
          }
        },
        "1f4bb7c4f5f6491d9be0d3c613e26a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d36a40f9c345199d3c5f778e4e3725",
            "placeholder": "​",
            "style": "IPY_MODEL_935515f70c5940508b107e99f8f28e7c",
            "value": " 447k/447k [00:00&lt;00:00, 2.67MB/s]"
          }
        },
        "2370176a0bb3478d908536e6dd494ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b9da1a406ba4e4bbe5931c613dd46fa",
              "IPY_MODEL_1287d9dafc6442248785ce19336fe1c7",
              "IPY_MODEL_0bbe8e0b088944c4a0e12c1ab19aa346"
            ],
            "layout": "IPY_MODEL_bd858f4659684677832751f978d826fa"
          }
        },
        "23e3b6f8b2554ed9b62befe0dc9e9965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25ff824b5e98433ab70192475e67e484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "272ba961dd654328bc1c421ccecf4f10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eed85eeca14493d89a528aa04672528": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f1ffeed60f84b43bb96dcd5985292fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_272ba961dd654328bc1c421ccecf4f10",
            "placeholder": "​",
            "style": "IPY_MODEL_23e3b6f8b2554ed9b62befe0dc9e9965",
            "value": " 500/500 [00:00&lt;00:00, 7325.53 examples/s]"
          }
        },
        "3112d369e376465d83b2d31f1d95ea20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a232d8379948e18c5451cf1e105a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67e792a2cbe14b94985e9a4bfb2dd908",
              "IPY_MODEL_5e84a6b2241b4bd599e2b530c7a22998",
              "IPY_MODEL_1f4bb7c4f5f6491d9be0d3c613e26a16"
            ],
            "layout": "IPY_MODEL_c1cc394d13fe4fe5ae4b3567faea7047"
          }
        },
        "35817d15a3e84eefa7e1883fdf02ec66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a8056efd9c416ca762e8bce9e36363",
            "placeholder": "​",
            "style": "IPY_MODEL_e147f8a527264645923f548e31b29e56",
            "value": "README.md: 100%"
          }
        },
        "369447a646d94ae2a4e4e8254f3da18d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a677f78e9e94e0aaec34ce4c2fe6eae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af438147c7d4357a48744c234d4daf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4118097744b8444490e87a085fd06527": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_578aa4c9063041e09f30d93df95a3acf",
            "placeholder": "​",
            "style": "IPY_MODEL_1e0c6a76b58f428b99ad438bd29adb6b",
            "value": " 447k/447k [00:00&lt;00:00, 3.13MB/s]"
          }
        },
        "4acf3ac9c4904f22881b819394901a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25ff824b5e98433ab70192475e67e484",
            "max": 446564,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07a5e2ad865a4438a33b5c2ad7dcc12b",
            "value": 446564
          }
        },
        "4f081aa287a84f79b4b21873bce74d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fd051c316334259b273142257600b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9072b751865145b9a2a505e3fa39d9f2",
              "IPY_MODEL_6b35e1244aa9427098567bcca63d3130",
              "IPY_MODEL_a6778c34deca4da69e1c9f4a51718bea"
            ],
            "layout": "IPY_MODEL_3a677f78e9e94e0aaec34ce4c2fe6eae"
          }
        },
        "4ffad2a8aa934fea9bf61a745c4f970f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5778820fe0824efdb9b5e25341cba6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578aa4c9063041e09f30d93df95a3acf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595b3e78969840e89d36fb66b4689d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595cb8ff681b476d8f9732f2de5b707a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a699a673c9e43e4a158a0e3f2458320": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a9a99b6209f4e1ba13f43a1b82dba94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad697bf784e4343a71ed4a8429d5680": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_634c44ae7fd34b80869fb357d53df800",
              "IPY_MODEL_4acf3ac9c4904f22881b819394901a84",
              "IPY_MODEL_73400c4522194cd293b94fb5614a9c38"
            ],
            "layout": "IPY_MODEL_a0e78ba61d494bbf82bba5fc055c81b3"
          }
        },
        "5af6779722a44597a337fb270501c253": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b9da1a406ba4e4bbe5931c613dd46fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b0d76f2d054c18b7c13fc94956a489",
            "placeholder": "​",
            "style": "IPY_MODEL_f8b286c4b1cd48a89baf9e341d26e2fb",
            "value": "Generating test split: 100%"
          }
        },
        "5c8136ef087041f1890cca6b1baf2830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e84a6b2241b4bd599e2b530c7a22998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595b3e78969840e89d36fb66b4689d7d",
            "max": 446564,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_009d2be74db447b2874d2b5f8613de8e",
            "value": 446564
          }
        },
        "634c44ae7fd34b80869fb357d53df800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3604a3bb4244b49a580688bd61d25ef",
            "placeholder": "​",
            "style": "IPY_MODEL_fb77790ad7914a32acf446e29d4e33f3",
            "value": "test.jsonl: 100%"
          }
        },
        "67e792a2cbe14b94985e9a4bfb2dd908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13763b9f9071419fbafbf6cc503cc12b",
            "placeholder": "​",
            "style": "IPY_MODEL_a0a2994ed91640ca99818fe2fcca1f80",
            "value": "test.jsonl: 100%"
          }
        },
        "6a68e62ccd07428298385d21a37e3a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c1a01dfd894445bca9d77270d68d91",
            "placeholder": "​",
            "style": "IPY_MODEL_4ffad2a8aa934fea9bf61a745c4f970f",
            "value": "test.jsonl: 100%"
          }
        },
        "6a7650aadec84052aa32288292f280d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f637abfc0f845c5bcb891bca701583b",
            "max": 412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd716e363fb9497a8afbd6bfe5acab2e",
            "value": 412
          }
        },
        "6b35e1244aa9427098567bcca63d3130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c8136ef087041f1890cca6b1baf2830",
            "max": 412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f0ed7fd15d94318a003dd5b713ac0f0",
            "value": 412
          }
        },
        "70d9911202474136939d36c1a32b6f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73400c4522194cd293b94fb5614a9c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff658e1d52324fcf9596c1ddce033527",
            "placeholder": "​",
            "style": "IPY_MODEL_ff3ac586a9874232bda30c66dbbca79f",
            "value": " 447k/447k [00:00&lt;00:00, 5.98MB/s]"
          }
        },
        "7dcf735613f44ebd8d61fd96a1df133f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e18a3ec0f0ae4748a55a404575184ead",
            "max": 412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1869b6b4e5d45149def98c6cf21a303",
            "value": 412
          }
        },
        "7f637abfc0f845c5bcb891bca701583b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b0d76f2d054c18b7c13fc94956a489": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ff5895a64e444e7a8f7bbfc654a9d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9072b751865145b9a2a505e3fa39d9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5778820fe0824efdb9b5e25341cba6a2",
            "placeholder": "​",
            "style": "IPY_MODEL_09d6335dd8a54ca49c4a763d47a2d7f3",
            "value": "README.md: 100%"
          }
        },
        "935515f70c5940508b107e99f8f28e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97dd122e0d6c43ddb0ac572d0cf4ea50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b025a53cf3f496a8c7750709e37c2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e1dc804e9344baf839699e91b2d1197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2f6e2076e1745b4b8bf65e1898303e4",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a699a673c9e43e4a158a0e3f2458320",
            "value": 500
          }
        },
        "9f0ed7fd15d94318a003dd5b713ac0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0a2994ed91640ca99818fe2fcca1f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e78ba61d494bbf82bba5fc055c81b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1869b6b4e5d45149def98c6cf21a303": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2f6e2076e1745b4b8bf65e1898303e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6778c34deca4da69e1c9f4a51718bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc9ccf8408649fe878ce8d43fe709e2",
            "placeholder": "​",
            "style": "IPY_MODEL_97dd122e0d6c43ddb0ac572d0cf4ea50",
            "value": " 412/412 [00:00&lt;00:00, 37.2kB/s]"
          }
        },
        "a99c814584414cf58d6bfc1078b03f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbce950cd56142d8832b55cc5d75471d",
            "placeholder": "​",
            "style": "IPY_MODEL_d1b28b9e2979421481454b4fbb43b698",
            "value": " 412/412 [00:00&lt;00:00, 8.53kB/s]"
          }
        },
        "ab29e4e2d4e04ca8b2dc828b11df076d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3112d369e376465d83b2d31f1d95ea20",
            "placeholder": "​",
            "style": "IPY_MODEL_5af6779722a44597a337fb270501c253",
            "value": "README.md: 100%"
          }
        },
        "ab99e55827a540be871c1f28c873e57e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42309d21e594a239f56fa73672d12ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369447a646d94ae2a4e4e8254f3da18d",
            "max": 446564,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee6aa96ce57041b7b63ac2d7f10052f1",
            "value": 446564
          }
        },
        "bd858f4659684677832751f978d826fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1cc394d13fe4fe5ae4b3567faea7047": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c772d846930646cdba6a5eca507ee6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb47df580dd9476baac2a2d306fd81a5",
            "placeholder": "​",
            "style": "IPY_MODEL_70d9911202474136939d36c1a32b6f4c",
            "value": "Generating test split: 100%"
          }
        },
        "c9d36a40f9c345199d3c5f778e4e3725": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc9ccf8408649fe878ce8d43fe709e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1b28b9e2979421481454b4fbb43b698": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6c1a01dfd894445bca9d77270d68d91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e147f8a527264645923f548e31b29e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e18a3ec0f0ae4748a55a404575184ead": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e230f8df0f274a69a25456f56797150b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3604a3bb4244b49a580688bd61d25ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a8056efd9c416ca762e8bce9e36363": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5672049543d403fa763effa2ac75032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35817d15a3e84eefa7e1883fdf02ec66",
              "IPY_MODEL_6a7650aadec84052aa32288292f280d2",
              "IPY_MODEL_a99c814584414cf58d6bfc1078b03f68"
            ],
            "layout": "IPY_MODEL_e5f256337399421e87b3ba1f6bf3e1d5"
          }
        },
        "e5f256337399421e87b3ba1f6bf3e1d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e990b721c0ab42ef99c16e71ded08485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c772d846930646cdba6a5eca507ee6b0",
              "IPY_MODEL_1e4615cbaab246e89b083b4d7d10ff31",
              "IPY_MODEL_2f1ffeed60f84b43bb96dcd5985292fb"
            ],
            "layout": "IPY_MODEL_1cbac43a26a6433daaab1d3a3dcc0cdf"
          }
        },
        "eb47df580dd9476baac2a2d306fd81a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed6bc8078de3465b87a7f88fe6428170": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee6aa96ce57041b7b63ac2d7f10052f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f02796974bbe45c3a6998ebdf35d025c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595cb8ff681b476d8f9732f2de5b707a",
            "placeholder": "​",
            "style": "IPY_MODEL_4f081aa287a84f79b4b21873bce74d24",
            "value": " 412/412 [00:00&lt;00:00, 38.7kB/s]"
          }
        },
        "f1c0507bfbb347a99758b5fc45520b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a68e62ccd07428298385d21a37e3a84",
              "IPY_MODEL_b42309d21e594a239f56fa73672d12ef",
              "IPY_MODEL_4118097744b8444490e87a085fd06527"
            ],
            "layout": "IPY_MODEL_ab99e55827a540be871c1f28c873e57e"
          }
        },
        "f67d88767ef249a08f1c144e05fd75c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18eb7562c0eb4eec87be3e3d3e87b360",
            "placeholder": "​",
            "style": "IPY_MODEL_8ff5895a64e444e7a8f7bbfc654a9d42",
            "value": "Generating test split: 100%"
          }
        },
        "f8b286c4b1cd48a89baf9e341d26e2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb77790ad7914a32acf446e29d4e33f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbce950cd56142d8832b55cc5d75471d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd716e363fb9497a8afbd6bfe5acab2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fef6254a547b4d0cbc55103db2b0ca59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3ac586a9874232bda30c66dbbca79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff658e1d52324fcf9596c1ddce033527": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
